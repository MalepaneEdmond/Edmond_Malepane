{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MalepaneEdmond/Edmond_Malepane/blob/main/My_project_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT4KrE3r6E9i",
        "outputId": "e1325215-6be2-405e-e2ab-be905fd8e644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The Codes\n",
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "# Initialize OpenAI API\n",
        "openai.api_key = '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'\n",
        "\n",
        "# Create the dataframe\n",
        "data = {\n",
        "    'Price': [21269, 16293, 27918, 14924, 20730, 5983, 10664, 19066, 5882, 21222],\n",
        "    'Age': [5, 9, 3, 8, 3, 8, 3, 8, 10, 10]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create a DataFrame to store the results for CSV export\n",
        "results_df = pd.DataFrame(columns=['Iteration', 'Question', 'Answer'])\n",
        "\n",
        "# List of questions to ask ChatGPT with context about the dataset\n",
        "questions = [\n",
        "    f\"Given a dataset of car prices and ages: {data}, what is the average price?\",\n",
        "    f\"Given a dataset of car prices and ages: {data}, what is the maximum age?\",\n",
        "    f\"Given a dataset of car prices and ages: {data}, what is the average price for cars priced below $10,000?\",\n",
        "    f\"Given a dataset of car prices and ages: {data}, what is the correlation value between price and age?\",\n",
        "    f\"Given a dataset of car prices and ages: {data}, how many cars are priced above $15,000?\",\n",
        "    f\"Given a dataset of car prices and ages: {data}, what is the minimum price of the cars?\",\n",
        "    f\"Given a dataset of car prices and ages: {data}, what is the standard deviation of the car prices?\",\n",
        "    f\"Given a dataset of car prices and ages: {data}, how many cars are older than 5 years?\",\n",
        "    f\"Given a dataset of car prices and ages: {data}, what is the median age of the cars?\",\n",
        "    f\"Given a dataset of car prices and ages: {data}, what is the range of the car prices?\"\n",
        "]\n",
        "\n",
        "# Iterate 10 times\n",
        "for i in range(10):\n",
        "    # Use OpenAI API to get answers to the questions\n",
        "    phrased_answers = {}\n",
        "    for question in questions:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",  # Use the appropriate engine/model identifier for ChatGPT-4\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": question}\n",
        "            ]\n",
        "        )\n",
        "        phrased_answers[question] = response['choices'][0]['message']['content']\n",
        "\n",
        "    # Store the questions and answers in the results DataFrame\n",
        "    for q, a in phrased_answers.items():\n",
        "        results_df = results_df.append({\n",
        "            'Iteration': f\"Iteration {i + 1}\",\n",
        "            'Question': q,\n",
        "            'Answer': a\n",
        "        }, ignore_index=True)\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('phrased_answers.csv', index=False)\n",
        "\n"
      ],
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "# Initialize OpenAI API\n",
        "openai.api_key = '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'  # Replace 'YOUR_API_KEY' with your actual API key\n",
        "\n",
        "# Context about the dataset\n",
        "context = \"\"\"\n",
        "... [Your dataset description here] ...\n",
        "The dataset includes 146,028 dyads of players and referees, with details from players, details from referees,\n",
        "and details regarding the interactions of player-referees.\n",
        "\"\"\"\n",
        "\n",
        "# List of questions based on the dataset\n",
        "questions = [\n",
        "    \"What distribution should be specified for the red card outcome variable?\",\n",
        "    \"How can you address the non-independence of data points in the analysis?\",\n",
        "    \"How many control variables or covariates should be incorporated into the model?\",\n",
        "    \"What statistical method should be employed for the analysis?\",\n",
        "    \"What could be the resulting odds ratio from the analysis?\"\n",
        "]\n",
        "\n",
        "# Create a DataFrame to store the results for CSV export\n",
        "results_df = pd.DataFrame(columns=['Iteration', 'Question', 'Answer'])\n",
        "\n",
        "# Iterate 10 times over the questions\n",
        "for iteration in range(1, 11):\n",
        "    for question in questions:\n",
        "        full_prompt = context + question\n",
        "\n",
        "        # Use OpenAI API to get an answer to the question\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": full_prompt}\n",
        "            ]\n",
        "        )\n",
        "        answer = response.choices[0].message.content  # Extracting the generated answer\n",
        "\n",
        "        # Store the iteration number, question, and answer in the results DataFrame\n",
        "        results_df = results_df.append({\n",
        "            'Iteration': iteration,\n",
        "            'Question': question,\n",
        "            'Answer': answer\n",
        "        }, ignore_index=True)\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('/content/phrased_answers.csv', index=False)\n",
        "\n",
        "print(\"Done! The answers have been saved to 'phrased_answers.csv'.\")\n",
        "\n",
        "\n"
      ],
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Box plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data provided for the box-and-whisker plot\n",
        "chatgpt_4w_covariates = [5, 4, 6, 1, 7, 5, 6, 4, 5, 5]\n",
        "chatgpt_4_covariates = [5, 6, 4, 5, 3, 4, 5, 4, 3, 4]\n",
        "humans_covariates = [7, 6, 6, 3, 4, 3, 6, 3, 6, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 2, 3, 1, 2, 1, 2, 1, 6]\n",
        "\n",
        "# Creating the box-and-whisker plot with specified colors\n",
        "plt.figure(figsize=(10, 6))\n",
        "bplot = plt.boxplot(\n",
        "    [chatgpt_4w_covariates, chatgpt_4_covariates, humans_covariates],\n",
        "    labels=[\"ChatGPT-4W\", \"ChatGPT-4\", \"Humans\"],\n",
        "    patch_artist=True  # Enables filling of the boxes with color\n",
        ")\n",
        "\n",
        "# Specifying colors for each box\n",
        "colors = ['blue', 'green', 'purple']\n",
        "for patch, color in zip(bplot['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "\n",
        "plt.title('Colored Box-and-Whisker Plot of Number of Covariates')\n",
        "plt.xlabel('Groups')\n",
        "plt.ylabel('Number of Covariates')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "owKsb_xxiI6t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1sNGnJl8tlfZkGALDurdRWReTL70rVLEE",
      "authorship_tag": "ABX9TyPO0w75UqXdfgczHRXTsYM8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
